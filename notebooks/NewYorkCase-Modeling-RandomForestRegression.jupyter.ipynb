{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Modeling Heating Problems in Manhattan\n",
    "\n",
    "In this notebook we will continue to use the data from the first notebook, a combination of NYC 311 Complaints data and PLUTO land use and geographic data. The purpose of this notebook is to demonstrate the methodology of building a predictive model with Spark.\n",
    "\n",
    "***\n",
    "\n",
    "## Read the Data\n",
    "We previously saved our data in the Object Store; the following code provides the appropriate credentials to be able to access and read our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('NewYorkCase').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "modelData=spark.read.csv('../datasets/mnModelData.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------+---------+----------+-----------+---------+--------+\n",
      "|  Zip|ZipHeatingCnt|Borough|BldgCount|avgBldgAge|avgBldgArea|  avgXcrd| avgYCrd|\n",
      "+-----+-------------+-------+---------+----------+-----------+---------+--------+\n",
      "|10012|            1|     MN|     1168|     143.0|    23483.0| 984755.0|203548.0|\n",
      "|10011|            1|     MN|     2080|     145.0|    26692.0| 984425.0|209172.0|\n",
      "|10014|            1|     MN|     1959|     148.0|    17391.0| 982940.0|206799.0|\n",
      "|10463|            1|     MN|      220|     204.0|    15722.0|1008961.0|258548.0|\n",
      "|10003|            3|     MN|     1881|     139.0|    28940.0| 987540.0|205715.0|\n",
      "|10040|            1|     MN|      429|     188.0|    40602.0|1003705.0|251912.0|\n",
      "|10022|            3|     MN|     1101|     189.0|    82191.0| 993309.0|215562.0|\n",
      "|10065|            1|     MN|     1052|     127.0|    42394.0| 993913.0|217993.0|\n",
      "|10035|            3|     MN|     1514|     443.0|    13521.0|1001455.0|231364.0|\n",
      "|10028|            1|     MN|     1207|     103.0|    31134.0| 997215.0|222054.0|\n",
      "|10033|            3|     MN|      782|     229.0|    30288.0|1002319.0|248810.0|\n",
      "|10031|            2|     MN|     1613|     162.0|    17127.0| 998628.0|240039.0|\n",
      "|10027|            1|     MN|     2258|     266.0|    18990.0| 998178.0|234378.0|\n",
      "|10037|            1|     MN|      381|     303.0|    35681.0|1000951.0|235105.0|\n",
      "|10024|            2|     MN|     1760|     125.0|    27681.0| 991048.0|225769.0|\n",
      "|10026|            1|     MN|     1032|     226.0|    17527.0| 997294.0|231873.0|\n",
      "|10025|            1|     MN|     1593|     158.0|    46590.0| 993282.0|230084.0|\n",
      "|10029|            2|     MN|     1617|     340.0|    28255.0| 999846.0|228126.0|\n",
      "|10013|            1|     MN|     1643|     190.0|    31299.0| 983408.0|201464.0|\n",
      "|10019|            1|     MN|     1100|     206.0|    97725.0| 988181.0|217985.0|\n",
      "+-----+-------------+-------+---------+----------+-----------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Zip: integer (nullable = true)\n",
      " |-- ZipHeatingCnt: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- BldgCount: integer (nullable = true)\n",
      " |-- avgBldgAge: double (nullable = true)\n",
      " |-- avgBldgArea: double (nullable = true)\n",
      " |-- avgXcrd: double (nullable = true)\n",
      " |-- avgYCrd: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelData.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature Selection\n",
    "\n",
    "We decided to keep things simple for this example problem so don't have too many to choose from but let's evaluate our features to see which should be included. We can use Pearson's correlation to do this. This calculation takes two numeric columns of equal length and returns a value between 1 and -1. If something close to 1 is returned, there is a strong positive correlation, meaning that if the value in one of the columns increases, so will the value in the other column. A -1 value would indicate the opposite, as the value in one column increases, the other would decrease. A result close to 0 would indicate there is no clear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018134457383525877"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelData.stat.corr(\"ZipHeatingCnt\", \"BldgCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1455650158192505"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelData.stat.corr(\"ZipHeatingCnt\", \"avgBldgAge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001339762980715712"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelData.stat.corr(\"ZipHeatingCnt\", \"avgBldgArea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This shows that there is a medium negative correlation between the number of complaints and the average building area; that the larger the average building area, the lower the number of complaints. To improve the model, it might be worth understanding what times of buildings these are, e.g. are they business rather than residential?\n",
    "\n",
    "There are very low correlations for both building count and average building age (if any) indicating they are likely to only add little value if we include them in our model and we definitely couldn't use these as on there own to predict the number of complaints.\n",
    "\n",
    "We will go ahead with all three features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Random Forest Regression Modeling\n",
    "\n",
    "The target variable we wish to predict is a linear value, therefore Random Forest Regression is an ideal candidate.\n",
    "\n",
    "We're not going to do any further Feature Extraction or Transformations in this notebook so let's remind ourselves of our input data we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "FeatureAssembler=VectorAssembler(inputCols=['avgBldgArea','avgBldgAge','BldgCount'], outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#modelDataTran = FeatureAssembler.transform(modelData)\n",
    "#modelDataTran = modelDataTran.select(['features', 'ZipHeatingCnt'])\n",
    "#modelDataTran.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    " \n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "#featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(modelDataTran)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = modelData.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol=\"features\",labelCol='ZipHeatingCnt')\n",
    "#rf = RandomForestRegressor(featuresCol=\"features\",labelCol='ZipHeatingCnt')\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "#pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "pipeline = Pipeline(stages=[FeatureAssembler, rf])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "RF_Model = pipeline.fit(trainingData)\n",
    "#RF_Model = rf.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+----------------------+\n",
      "|prediction        |ZipHeatingCnt|features              |\n",
      "+------------------+-------------+----------------------+\n",
      "|1367.7166666666667|1360         |[28940.0,139.0,1881.0]|\n",
      "|163.95            |3            |[293074.0,264.0,119.0]|\n",
      "|640.5383333333333 |7            |[348700.0,131.0,78.0] |\n",
      "|435.58333333333337|23           |[150624.0,230.0,229.0]|\n",
      "|1589.8079166666669|1609         |[23049.0,291.0,1343.0]|\n",
      "+------------------+-------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_train = RF_Model.transform(trainingData)\n",
    "preds_train.select(\"prediction\",\"ZipHeatingCnt\",\"features\").show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "In order to see how well our model works, we test is. Both our training data and test data have the correct results so we are able to compare the two for each row to understand the model's accuracy. \n",
    "\n",
    "In production, as you are trying to prediction something before it happens, you wouldn't have this so you would need to continue to test offline to ensure that your model is still valid.\n",
    "\n",
    "We can going to generate predictions for both our training data and testing data to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------------------+\n",
      "|prediction|ZipHeatingCnt|features              |\n",
      "+----------+-------------+----------------------+\n",
      "|1.25      |1            |[26692.0,145.0,2080.0]|\n",
      "|1.2       |1            |[51857.0,199.0,1409.0]|\n",
      "|1.25      |1            |[97725.0,206.0,1100.0]|\n",
      "|1.4       |1            |[18990.0,266.0,2258.0]|\n",
      "|1.15      |1            |[31134.0,103.0,1207.0]|\n",
      "+----------+-------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_train = RF_Model.transform(trainingData)\n",
    "preds_train.select(\"prediction\",\"ZipHeatingCnt\",\"features\").show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+\n",
      "|prediction|ZipHeatingCnt|            features|\n",
      "+----------+-------------+--------------------+\n",
      "|      1.25|            3|[28940.0,139.0,18...|\n",
      "|       1.2|            1|[23483.0,143.0,11...|\n",
      "|      1.35|            1|[31299.0,190.0,16...|\n",
      "|      1.55|            1|[17391.0,148.0,19...|\n",
      "|      1.25|            2|[37667.0,122.0,11...|\n",
      "+----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 1.4346\n",
      "RandomForestRegressionModel (uid=rfr_23762f363ea4) with 20 trees\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = RF_Model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"ZipHeatingCnt\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"ZipHeatingCnt\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "rfModel = RF_Model.stages[1]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "RMSE values are the same unit as the label feature. Therefore, one way to understand if these are good values, would be to look at the average label value; if a prediction that was smaller or larger by the RMSE value is deemed acceptable, then it is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg(ZipHeatingCnt)|\n",
      "+------------------+\n",
      "|1.4166666666666667|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg\n",
    "preds_train.agg(avg(col(\"ZipHeatingCnt\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ok, so we shouldn't use this predictive model in practice. Since we only have 43 rows in total, let's have a look at all the label and predictions to see how far off they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------+---------+----------+-----------+---------+--------+--------------------+----------+--------------------+\n",
      "|  Zip|ZipHeatingCnt|Borough|BldgCount|avgBldgAge|avgBldgArea|  avgXcrd| avgYCrd|            features|prediction|                diff|\n",
      "+-----+-------------+-------+---------+----------+-----------+---------+--------+--------------------+----------+--------------------+\n",
      "|10011|            1|     MN|     2080|     145.0|    26692.0| 984425.0|209172.0|[26692.0,145.0,20...|      1.25|                0.25|\n",
      "|10016|            1|     MN|     1409|     199.0|    51857.0| 989921.0|210948.0|[51857.0,199.0,14...|       1.2| 0.19999999999999996|\n",
      "|10019|            1|     MN|     1100|     206.0|    97725.0| 988181.0|217985.0|[97725.0,206.0,11...|      1.25|                0.25|\n",
      "|10027|            1|     MN|     2258|     266.0|    18990.0| 998178.0|234378.0|[18990.0,266.0,22...|       1.4|  0.3999999999999999|\n",
      "|10028|            1|     MN|     1207|     103.0|    31134.0| 997215.0|222054.0|[31134.0,103.0,12...|      1.15|  0.1499999999999999|\n",
      "|10029|            2|     MN|     1617|     340.0|    28255.0| 999846.0|228126.0|[28255.0,340.0,16...|       1.8|-0.19999999999999996|\n",
      "|10031|            2|     MN|     1613|     162.0|    17127.0| 998628.0|240039.0|[17127.0,162.0,16...|      1.75|               -0.25|\n",
      "|10033|            3|     MN|      782|     229.0|    30288.0|1002319.0|248810.0|[30288.0,229.0,78...|      2.45| -0.5499999999999998|\n",
      "|10037|            1|     MN|      381|     303.0|    35681.0|1000951.0|235105.0|[35681.0,303.0,38...|      1.55|                0.55|\n",
      "|10065|            1|     MN|     1052|     127.0|    42394.0| 993913.0|217993.0|[42394.0,127.0,10...|     1.125|               0.125|\n",
      "|10075|            2|     MN|      701|     127.0|    31987.0| 996129.0|221149.0|[31987.0,127.0,70...|     1.925|-0.07499999999999996|\n",
      "|10463|            1|     MN|      220|     204.0|    15722.0|1008961.0|258548.0|[15722.0,204.0,22...|       1.4|  0.3999999999999999|\n",
      "+-----+-------------+-------+---------+----------+-----------+---------+--------+--------------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_train.withColumn('diff', col('prediction')-col('ZipHeatingCnt')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "## Unseen Data\n",
    "\n",
    "Now we are replicating what would happen in practice, new data would be passed to the model and a prediction returned. This is the value that would be actioned on in production, i.e. the appropriate 311 agency would allocate the number of staff to particular zipcodes to meet the expected demand\n",
    "\n",
    "As before, let's read the data from Object store that we previously saved in the first notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mndf=spark.read.csv('../datasets/mnAgrData.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mndf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- ZipCode: integer (nullable = true)\n",
      " |-- BldgCount: integer (nullable = true)\n",
      " |-- avgBldgArea: double (nullable = true)\n",
      " |-- avgBldgAge: double (nullable = true)\n",
      " |-- avgXcrd: double (nullable = true)\n",
      " |-- avgYcrd: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mndf.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- ZipCode: integer (nullable = true)\n",
      " |-- BldgCount: integer (nullable = true)\n",
      " |-- avgBldgArea: double (nullable = true)\n",
      " |-- avgBldgAge: double (nullable = true)\n",
      " |-- avgXcrd: double (nullable = true)\n",
      " |-- avgYcrd: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mndfTran = FeatureAssembler.transform(mndf.filter(col('avgBldgAge')!='null'))\n",
    "mndfTran = mndf.filter(col('avgBldgAge')!='null')\n",
    "predMN = RF_Model.transform(mndfTran)\n",
    "predMN.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+-----------+----------+---------+--------+--------------------+----------+\n",
      "|Borough|ZipCode|BldgCount|avgBldgArea|avgBldgAge|  avgXcrd| avgYcrd|            features|prediction|\n",
      "+-------+-------+---------+-----------+----------+---------+--------+--------------------+----------+\n",
      "|     MN|  10119|        2|  1179439.0|      72.0| 988320.0|214761.0|[1179439.0,72.0,2.0]|     1.575|\n",
      "|     MN|  10069|       18|   325768.0|     571.0| 987269.0|222199.0|[325768.0,571.0,1...|      1.45|\n",
      "|     MN|  10003|     1881|    28940.0|     139.0| 987540.0|205715.0|[28940.0,139.0,18...|      1.25|\n",
      "|     MN|  10017|      490|   158786.0|     197.0| 991710.0|213682.0|[158786.0,197.0,4...|      1.65|\n",
      "|     MN|   null|      169|      357.0|    1958.0| 997644.0|217413.0|[357.0,1958.0,169.0]|      1.45|\n",
      "|     MN|  10019|     1100|    97725.0|     206.0| 988181.0|217985.0|[97725.0,206.0,11...|      1.25|\n",
      "|     MN|  10002|     1707|    25474.0|     231.0| 987075.0|200573.0|[25474.0,231.0,17...|       1.4|\n",
      "|     MN|  10013|     1643|    31299.0|     190.0| 983408.0|201464.0|[31299.0,190.0,16...|      1.35|\n",
      "|     MN|  10022|     1101|    82191.0|     189.0| 993309.0|215562.0|[82191.0,189.0,11...|      1.15|\n",
      "|     MN|  10020|       10|  1389742.0|      67.0| 989850.0|215751.0|[1389742.0,67.0,1...|     1.575|\n",
      "|     MN|  10123|        1|   491253.0|      85.0| 986806.0|213043.0| [491253.0,85.0,1.0]|     1.575|\n",
      "|     MN|  10044|       15|   617352.0|     431.0| 997790.0|216228.0|[617352.0,431.0,1...|      1.45|\n",
      "|     MN|  10037|      381|    35681.0|     303.0|1000951.0|235105.0|[35681.0,303.0,38...|      1.55|\n",
      "|     MN|  10006|       65|   151872.0|     380.0| 980541.0|197385.0|[151872.0,380.0,6...|      1.45|\n",
      "|     MN|  10009|     1343|    23049.0|     291.0| 989490.0|203592.0|[23049.0,291.0,13...|       1.5|\n",
      "|     MN|  10463|      220|    15722.0|     204.0|1008961.0|258548.0|[15722.0,204.0,22...|       1.4|\n",
      "|     MN|  10035|     1514|    13521.0|     443.0|1001455.0|231364.0|[13521.0,443.0,15...|      1.85|\n",
      "|     MN|  10282|       16|   443837.0|     140.0| 980493.0|201868.0|[443837.0,140.0,1...|       1.4|\n",
      "|     MN|  10040|      429|    40602.0|     188.0|1003705.0|251912.0|[40602.0,188.0,42...|      1.65|\n",
      "|     MN|  10075|      701|    31987.0|     127.0| 996129.0|221149.0|[31987.0,127.0,70...|     1.925|\n",
      "+-------+-------+---------+-----------+----------+---------+--------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predMN.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Save Model in ML repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'path': '/user-home/999/DSX_Projects/NYCVK/models/NYC-RF-Model/1',\n",
       " 'scoring_endpoint': 'https://dsxl-api/v3/project/score/Python27/spark-2.0/NYCVK/NYC-RF-Model/1'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dsx_ml.ml import save\n",
    "\n",
    "model_name = 'NYC-RF-Model'\n",
    "save(name = model_name,\n",
    "     model = RF_Model,\n",
    "     algorithm_type = 'Regression',\n",
    "     test_data = testData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Note above path and scoring_endpoint that you will use in following cell for REST API call\n",
    "For e.g. {'path': '/user-home/999/DSX_Projects/NYCVK/models/NYC-RF-Model/1',\n",
    " 'scoring_endpoint': 'https://dsxl-api/v3/project/score/Python27/spark-2.0/NYCVK/NYC-RF-Model/1'}\n",
    " \n",
    "\n",
    "## Test Model in Web UI\n",
    "\n",
    "Step1 Click on the project name \"NYC-case-new\" \n",
    "\n",
    "Step2 Go to \"Model\" part, find the mode \"NYC-RF-Model_v3\" and then select \"Test\".\n",
    "<img src=\"../datasets/ModelTest.png\">\n",
    "\n",
    "Step3 Input value for each features and then click on \"Submit\".\n",
    "<img src=\"../datasets/TestResult.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test Model in Restful API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------+---------+----------+-----------+--------+--------+\n",
      "|  Zip|ZipHeatingCnt|Borough|BldgCount|avgBldgAge|avgBldgArea| avgXcrd| avgYCrd|\n",
      "+-----+-------------+-------+---------+----------+-----------+--------+--------+\n",
      "|10012|            1|     MN|     1168|     143.0|    23483.0|984755.0|203548.0|\n",
      "|10011|            1|     MN|     2080|     145.0|    26692.0|984425.0|209172.0|\n",
      "+-----+-------------+-------+---------+----------+-----------+--------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelData.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "json_payload = [{\n",
    "    \"Zip\":10012,\n",
    "    \"Borough\":\"MN\",\n",
    "    \"BldgCount\":1168,\n",
    "    \"avgBldgAge\":143.0,\n",
    "    \"avgBldgArea\":23483.0,\n",
    "    \"avgXcrd\":984755.0,\n",
    "    \"avgYCrd\":203548.0\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "1. 1\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from pprint import pprint\n",
    "\n",
    "scoring_endpoint = 'https://dsxl-api/v3/project/score/Python27/spark-2.0/NYCVK/NYC-RF-Model/1'\n",
    "\n",
    "header_online = {'Content-Type': 'application/json', 'Authorization':os.environ['DSX_TOKEN']}\n",
    "\n",
    "response_scoring = requests.post(scoring_endpoint, json=json_payload, headers=header_online)\n",
    "\n",
    "response_dict = json.loads(response_scoring.content)\n",
    "print(\"Prediction\")\n",
    "\n",
    "n = 1\n",
    "for response in response_dict['object']['output']['predictions']:\n",
    "    print(\"{}. {}\".format(n,response))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7 with DSX Spark 2.0.2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
